
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation">
  <meta name="keywords" content="EXIM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/videos/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
    </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Zhengzhe Liu<sup>1</sup>,
            </span>
            <span class="author-block">
              Jingyu Hu<sup>1</sup>,
            </span>
            <span class="author-block">
              Ka-Hei Hui<sup>1</sup>,
            </span>
            <span class="author-block">
              Xiaojuan Qi<sup>2</sup>,
            </span>
            <span class="author-block">
              Daniel Cohen-Or<sup>3</sup>,
            </span>
            <span class="author-block">
              Chi-Wing Fu<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong <sup>2</sup>The University of Hong Kong</span>
            <span class="author-block"><sup>3</sup>Tel-Aviv University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
	      <span class="link-block">
                <a href="https://arxiv.org/abs/2209.04145"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/liuzhengzhe/EXIM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<div class="section demo">
		<br>
		<center><iframe width="896" height="504" src="https://www.youtube.com/embed/t82O0rLBgh8?si=P5CkJZ37z3JVl-5p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></center>
		<br>
	</div>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents a new text-guided technique for generating 3D shapes.
The technique leverages a hybrid 3D shape representation, namely EXIM,
combining the strengths of explicit and implicit representations. Specifically,
the explicit stage controls the topology of the generated 3D shapes and
enables local modifications, whereas the implicit stage refines the shape
and paints it with plausible colors. Also, the hybrid approach separates
the shape and color and generates color conditioned on shape to ensure
shape-color consistency. Unlike the existing state-of-the-art methods, we
achieve high-fidelity shape generation from natural-language descriptions
without the need for time-consuming per-shape optimization or reliance on
human-annotated texts during training or test-time optimization. Further,
we demonstrate the applicability of our approach to generate indoor scenes
with consistent styles using text-induced 3D shapes. Through extensive
experiments, we demonstrate the compelling quality of our results and the
high coherency of our generated shapes with the input texts, surpassing the
performance of existing methods by a significant margin. Codes and models
are released at https://github.com/liuzhengzhe/EXIM.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
          <figure>
            <img src="overview.PNG" width=100%/>
          </figure>
          <div class="content has-text-justified">
          <p>
             Overview of our approach. (a) The Explicit Diffusion Stage transforms the truncated signed distance field (TSDF) of the training shape $S$ into compact wavelet volumes $C$ and utilizes a 3D diffusion model with the U-Net architecture to learn the coarse shape $S_\text{coarse}$ conditioned on the text description $D$ with cross-attention modules. (b) The Implicit Refinement Stage refines the coarse shape $S_\text{coarse}$ to produce the fine shape $S_\text{fine}$ and generates colors on the surface to create the final result $S$. It employs a 3D convolutional encoder to extract features from multi-level feature maps and predicts the occupancy and RGB values at each query location $p$. The color prediction is also conditioned on the text $D$ using cross-attention modules.
          </p>
          </div>
      </div>
    </div>

    
    


    
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <figure>
          <img src="overview_mani.PNG" width=100%/>
        </figure>
        <div class="content has-text-justified">
          <p>
            Our pipeline for modifying (a) shape and (b) color. For shape, we expand the diffusion model to include two additional input channels, the mask $M$ and the unmasked partial shape $S^\prime$. We then fine-tune the model to fill in the masked areas. For color, we can either incorporate the new text features into the intermediate feature maps or directly generate color values within the regions specified by $M$, without the need for fine-tuning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
    
    

<section class="section">
<div class="section demo">
		<br>
		<center><iframe width="896" height="504" src="https://www.youtube.com/embed/-GDDfSM28tY?si=n2vmtfGaiE1uoVKy" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></center>
		<br>
	</div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2> -->

        <!-- Interpolating. -->
        <!-- <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="https://homes.cs.washington.edu/~kpar/nerfies/videos/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="https://homes.cs.washington.edu/~kpar/nerfies/videos/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


  <!-- </div>
</section> -->


<section class="section" id="Reference">
<div class="container is-max-desktop content">
    <h2 class="title">Reference </h2>
    <pre><code>@article{liu2023dreamstone,
  title={EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation},
  author={Liu, Zhengzhe and Hu, Jingyu and Ka, Hei-Hui and Qi, Xiaojuan and Daniel, Cohen-Or and Fu, Chi-Wing},
  journal={IEEE Transactions on Graphics (TOG)},
  volume={42},
  number={6},
  year={2023}
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The code for the website is borrowed from  <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
